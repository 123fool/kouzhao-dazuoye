# -*- coding: utf-8 -*-
"""
å£ç½©æ£€æµ‹è¯¾ç¨‹ä½œä¸š - å®Œæ•´å¯è¿è¡Œç‰ˆæœ¬
åŒ…å«ï¼š
1. æ•°æ®é›†æ„å»ºï¼ˆä»XMLæ ‡æ³¨æ„å»ºåˆ†ç±»æ•°æ®é›†ï¼‰
2. SVMæ¨¡å‹è®­ç»ƒï¼ˆç»å…¸æœºå™¨å­¦ä¹ ï¼‰
3. ResNet18æ¨¡å‹è®­ç»ƒï¼ˆæ·±åº¦å­¦ä¹ ï¼‰
4. å®Œæ•´çš„æ€§èƒ½è¯„ä¼°å’Œå¯è§†åŒ–

ä½¿ç”¨è¯´æ˜ï¼š
1. ä¿®æ”¹ ROOT å˜é‡ä¸ºä½ çš„æ•°æ®è·¯å¾„
2. è¿è¡Œï¼špython mask_detection_complete.py
"""

import os
import sys
import shutil
import random
import xml.etree.ElementTree as ET
import time
import copy
from collections import defaultdict

# å»¶è¿Ÿå¯¼å…¥numpyä»¥é¿å…DLLåŠ è½½é—®é¢˜
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None
    print("è­¦å‘Š: numpy ä¸å¯ç”¨")

from PIL import Image

# æ·±åº¦å­¦ä¹ åº“
try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader
    from torchvision import datasets, transforms, models
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("è­¦å‘Š: PyTorch ä¸å¯ç”¨ï¼Œå°†è·³è¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹")

# æœºå™¨å­¦ä¹ åº“
try:
    from sklearn.svm import SVC
    from sklearn.metrics import accuracy_score
    from joblib import dump, load
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("è­¦å‘Š: scikit-learn ä¸å¯ç”¨ï¼Œå°†è·³è¿‡SVMæ¨¡å‹")

# å›¾åƒå¤„ç†åº“
try:
    from skimage.io import imread
    from skimage.color import rgb2gray
    from skimage.transform import resize
    from skimage.feature import hog
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False
    print("è­¦å‘Š: scikit-image ä¸å¯ç”¨")

# å¯è§†åŒ–åº“ï¼ˆå¯é€‰ï¼‰
try:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("è­¦å‘Š: matplotlib ä¸å¯ç”¨ï¼Œå°†è·³è¿‡å¯è§†åŒ–")

# ========================= é…ç½®éƒ¨åˆ† =========================

# ğŸ”´ é‡è¦ï¼šä¿®æ”¹è¿™é‡Œä¸ºä½ çš„æ•°æ®è·¯å¾„
ROOT = r"E:\WorkSpace-Jiang\å£ç½©\é¢éƒ¨å£ç½©æ£€æµ‹æ•°æ®é›†"  # æ”¹ä¸ºä½ çš„æ•°æ®è·¯å¾„

IMG_DIR = os.path.join(ROOT, "images")
ANN_DIR = os.path.join(ROOT, "annotations")
DATASET_DIR = "dataset"
MODELS_DIR = "models"

# æ•°æ®é›†é…ç½®
random.seed(42)
if NUMPY_AVAILABLE and np is not None:
    np.random.seed(42)
if TORCH_AVAILABLE:
    torch.manual_seed(42)

CLASS_NAMES = ["with_mask", "without_mask", "mask_incorrect"]

# SVMå’ŒHOGå‚æ•°
IMG_SIZE_HOG = (128, 128)
HOG_PARAMS = dict(
    orientations=9,
    pixels_per_cell=(8, 8),
    cells_per_block=(2, 2),
    block_norm="L2-Hys",
)

# ========================= ç¬¬1éƒ¨åˆ†ï¼šæ•°æ®é›†æ„å»º =========================

def parse_annotation(xml_file):
    """è§£æVOCæ ¼å¼XMLæ–‡ä»¶"""
    try:
        tree = ET.parse(xml_file)
        root = tree.getroot()
        
        objects = []
        for obj in root.iter("object"):
            name = obj.find("name").text
            
            # æ ‡å‡†åŒ–ç±»å
            if name == "with_mask":
                cls = "with_mask"
            elif name == "without_mask":
                cls = "without_mask"
            else:
                cls = "mask_incorrect"
            
            bbox = obj.find("bndbox")
            xmin = int(bbox.find("xmin").text)
            ymin = int(bbox.find("ymin").text)
            xmax = int(bbox.find("xmax").text)
            ymax = int(bbox.find("ymax").text)
            
            objects.append((cls, xmin, ymin, xmax, ymax))
        
        filename_node = root.find("filename")
        filename = filename_node.text if filename_node is not None else None
        
        return filename, objects
    except Exception as e:
        print(f"è§£æå¤±è´¥ {xml_file}: {e}")
        return None, []


def build_classification_dataset():
    """æ„å»ºåˆ†ç±»æ•°æ®é›†ï¼šä»XML+åŸå›¾è£å‰ªäººè„¸ï¼ŒæŒ‰7:1.5:1.5åˆ’åˆ†"""
    print("\n" + "="*60)
    print("ç¬¬1æ­¥ï¼šæ„å»ºåˆ†ç±»æ•°æ®é›†")
    print("="*60)
    
    if not os.path.exists(IMG_DIR) or not os.path.exists(ANN_DIR):
        print(f"âŒ é”™è¯¯: æ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼")
        print(f"   IMG_DIR: {IMG_DIR}")
        print(f"   ANN_DIR: {ANN_DIR}")
        print(f"è¯·ä¿®æ”¹ ROOT å˜é‡ä¸ºæ­£ç¡®çš„æ•°æ®è·¯å¾„")
        return False
    
    # åˆ é™¤æ—§æ•°æ®é›†
    if os.path.exists(DATASET_DIR):
        shutil.rmtree(DATASET_DIR)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    for split in ["train", "val", "test"]:
        for cls in CLASS_NAMES:
            os.makedirs(os.path.join(DATASET_DIR, split, cls), exist_ok=True)
    
    # è§£ææ‰€æœ‰XMLå¹¶è£å‰ªäººè„¸
    all_crops = []
    xml_files = [f for f in os.listdir(ANN_DIR) if f.endswith('.xml')]
    
    print(f"å‘ç° {len(xml_files)} ä¸ªXMLæ ‡æ³¨æ–‡ä»¶")
    
    for i, xml_name in enumerate(xml_files):
        if (i + 1) % 100 == 0:
            print(f"  å¤„ç†ä¸­... {i+1}/{len(xml_files)}")
        
        xml_path = os.path.join(ANN_DIR, xml_name)
        filename, objects = parse_annotation(xml_path)
        
        if not filename:
            continue
        
        # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶
        img_path = os.path.join(IMG_DIR, filename)
        if not os.path.exists(img_path):
            # å°è¯•å…¶ä»–æ ¼å¼
            base = os.path.splitext(filename)[0]
            found = False
            for ext in [".jpg", ".jpeg", ".png", ".JPG", ".PNG"]:
                alt = os.path.join(IMG_DIR, base + ext)
                if os.path.exists(alt):
                    img_path = alt
                    found = True
                    break
            if not found:
                continue
        
        try:
            img = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"  âš  æ— æ³•æ‰“å¼€å›¾åƒ: {img_path}")
            continue
        
        img_w, img_h = img.size
        ext = os.path.splitext(img_path)[1]
        
        # è£å‰ªæ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
        for idx, (cls, xmin, ymin, xmax, ymax) in enumerate(objects):
            xmin = max(0, xmin)
            ymin = max(0, ymin)
            xmax = min(img_w - 1, xmax)
            ymax = min(img_h - 1, ymax)
            
            if xmax <= xmin or ymax <= ymin:
                continue
            
            crop = img.crop((xmin, ymin, xmax, ymax))
            save_name = f"{os.path.splitext(xml_name)[0]}_{idx}{ext}"
            all_crops.append((crop, cls, save_name))
    
    if len(all_crops) == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰è§£æåˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ï¼")
        return False
    
    # æ•°æ®åˆ’åˆ†
    random.shuffle(all_crops)
    n = len(all_crops)
    n_train = int(n * 0.7)
    n_val = int(n * 0.15)
    
    train_set = all_crops[:n_train]
    val_set = all_crops[n_train:n_train + n_val]
    test_set = all_crops[n_train + n_val:]
    
    # ä¿å­˜æ•°æ®é›†
    split_data = {"train": train_set, "val": val_set, "test": test_set}
    for split, samples in split_data.items():
        for crop, cls, name in samples:
            save_path = os.path.join(DATASET_DIR, split, cls, name)
            crop.save(save_path)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\nâœ“ æ•°æ®é›†æ„å»ºå®Œæˆï¼")
    for split in ["train", "val", "test"]:
        total = sum(
            len(os.listdir(os.path.join(DATASET_DIR, split, cls)))
            for cls in CLASS_NAMES
        )
        print(f"  {split.upper():5s} é›†: {total:4d} æ ·æœ¬", end="")
        
        for cls in CLASS_NAMES:
            count = len(os.listdir(os.path.join(DATASET_DIR, split, cls)))
            print(f"  | {cls}: {count:3d}", end="")
        print()
    
    return True


# ========================= ç¬¬2éƒ¨åˆ†ï¼šSVMæ¨¡å‹ =========================

def load_hog_features(split):
    """æå–HOGç‰¹å¾"""
    X, y = [], []
    
    for label_idx, cls in enumerate(CLASS_NAMES):
        folder = os.path.join(DATASET_DIR, split, cls)
        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]
        
        for fname in files:
            try:
                path = os.path.join(folder, fname)
                img = imread(path)
                
                if img.ndim == 3:
                    img_gray = rgb2gray(img)
                else:
                    img_gray = img
                
                img_resized = resize(img_gray, IMG_SIZE_HOG, anti_aliasing=True)
                feat = hog(img_resized, **HOG_PARAMS)
                X.append(feat)
                y.append(label_idx)
            except Exception as e:
                pass
    
    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)


def train_svm():
    """è®­ç»ƒSVMæ¨¡å‹"""
    if not SKLEARN_AVAILABLE or not SKIMAGE_AVAILABLE:
        print("\nâš  SVMæ¨¡å‹è·³è¿‡: ç¼ºå°‘å¿…è¦çš„åº“")
        return None
    
    print("\n" + "="*60)
    print("ç¬¬2æ­¥ï¼šè®­ç»ƒSVMæ¨¡å‹ (HOG + SVM)")
    print("="*60)
    
    print("æå–HOGç‰¹å¾ä¸­...")
    X_train, y_train = load_hog_features("train")
    X_val, y_val = load_hog_features("val")
    X_test, y_test = load_hog_features("test")
    
    print(f"âœ“ ç‰¹å¾æå–å®Œæˆ")
    print(f"  HOGç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
    print(f"  è®­ç»ƒæ ·æœ¬: {X_train.shape[0]}")
    
    print("\nè®­ç»ƒSVMæ¨¡å‹ä¸­...")
    svm = SVC(kernel="rbf", C=10, gamma="scale", verbose=1)
    svm.fit(np.vstack([X_train, X_val]), np.hstack([y_train, y_val]))
    
    # è¯„ä¼°
    y_pred = svm.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nâœ“ SVMè®­ç»ƒå®Œæˆï¼")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    print("\n  æŒ‰ç±»åˆ«å‡†ç¡®ç‡:")
    for i, cls_name in enumerate(CLASS_NAMES):
        mask = y_test == i
        if np.sum(mask) > 0:
            acc = np.sum(y_pred[mask] == y_test[mask]) / np.sum(mask)
            print(f"    {cls_name:20s}: {acc:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs(MODELS_DIR, exist_ok=True)
    dump(svm, os.path.join(MODELS_DIR, "svm_hog_mask.joblib"))
    print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜: {MODELS_DIR}/svm_hog_mask.joblib")
    
    return {"name": "SVM", "accuracy": accuracy, "y_true": y_test, "y_pred": y_pred}


# ========================= ç¬¬3éƒ¨åˆ†ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹ =========================

def train_resnet18(num_epochs=5):
    """è®­ç»ƒResNet18æ¨¡å‹"""
    if not TORCH_AVAILABLE:
        print("\nâš  ResNet18æ¨¡å‹è·³è¿‡: PyTorchä¸å¯ç”¨")
        return None
    
    print("\n" + "="*60)
    print("ç¬¬3æ­¥ï¼šè®­ç»ƒResNet18æ¨¡å‹ (æ·±åº¦å­¦ä¹ )")
    print("="*60)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®å˜æ¢
    data_transforms = {
        "train": transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        "val": transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        "test": transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }
    
    # åŠ è½½æ•°æ®é›†
    image_datasets = {
        x: datasets.ImageFolder(
            root=os.path.join(DATASET_DIR, x),
            transform=data_transforms[x]
        )
        for x in ["train", "val", "test"]
    }
    
    dataloaders = {
        x: DataLoader(image_datasets[x], batch_size=32, shuffle=(x == "train"), num_workers=0)
        for x in ["train", "val", "test"]
    }
    
    dataset_sizes = {x: len(image_datasets[x]) for x in ["train", "val", "test"]}
    print(f"\næ•°æ®é›†å¤§å°: {dataset_sizes}")
    
    # æ„å»ºæ¨¡å‹
    print("\nåŠ è½½é¢„è®­ç»ƒResNet18...")
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    
    # å†»ç»“ç‰¹å¾å±‚ï¼Œåªè®­ç»ƒåˆ†ç±»å±‚
    for param in model.parameters():
        param.requires_grad = False
    
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, len(CLASS_NAMES))
    model = model.to(device)
    
    # è®­ç»ƒé…ç½®
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)
    
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    
    # è®­ç»ƒå¾ªç¯
    print(f"\nå¼€å§‹è®­ç»ƒ ({num_epochs} epochs)...")
    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")
        
        for phase in ["train", "val"]:
            if phase == "train":
                model.train()
            else:
                model.eval()
            
            running_loss = 0.0
            running_corrects = 0
            
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                optimizer.zero_grad()
                
                with torch.set_grad_enabled(phase == "train"):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    
                    if phase == "train":
                        loss.backward()
                        optimizer.step()
                
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            
            if phase == "train":
                scheduler.step()
            
            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]
            
            print(f"  {phase.upper():5s} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}")
            
            if phase == "val" and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
    
    # åŠ è½½æœ€ä½³æƒé‡
    model.load_state_dict(best_model_wts)
    
    # æµ‹è¯•è¯„ä¼°
    print("\n" + "-"*60)
    print("åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
    
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for inputs, labels in dataloaders["test"]:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            
            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
    
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)
    
    accuracy = np.sum(all_preds == all_labels) / len(all_labels)
    
    print(f"\nâœ“ ResNet18è®­ç»ƒå®Œæˆï¼")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    print("\n  æŒ‰ç±»åˆ«å‡†ç¡®ç‡:")
    for i, cls_name in enumerate(CLASS_NAMES):
        mask = all_labels == i
        if np.sum(mask) > 0:
            acc = np.sum(all_preds[mask] == all_labels[mask]) / np.sum(mask)
            print(f"    {cls_name:20s}: {acc:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    os.makedirs(MODELS_DIR, exist_ok=True)
    torch.save(model.state_dict(), os.path.join(MODELS_DIR, "resnet18_mask.pth"))
    print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜: {MODELS_DIR}/resnet18_mask.pth")
    
    return {"name": "ResNet18", "accuracy": accuracy, "y_true": all_labels, "y_pred": all_preds}


# ========================= ç¬¬4éƒ¨åˆ†ï¼šæ€§èƒ½å¯¹æ¯”ä¸å¯è§†åŒ– =========================

def print_results_summary(results):
    """æ‰“å°ç»“æœæ€»ç»“"""
    print("\n" + "="*60)
    print("æœ€ç»ˆç»“æœæ€»ç»“")
    print("="*60)
    
    if results:
        print("\næ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”:")
        for result in results:
            if result:
                print(f"  {result['name']:15s}: {result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)")
        
        if len(results) == 2 and results[0] and results[1]:
            diff = abs(results[1]['accuracy'] - results[0]['accuracy'])
            better = results[1]['name'] if results[1]['accuracy'] > results[0]['accuracy'] else results[0]['name']
            print(f"\n  æ€§èƒ½å·®å¼‚: {diff:.4f}")
            print(f"  æ›´ä¼˜ç§€çš„æ¨¡å‹: {better}")


def plot_confusion_matrix(y_true, y_pred, model_name):
    """ç®€å•çš„æ··æ·†çŸ©é˜µæ‰“å°"""
    if not MATPLOTLIB_AVAILABLE:
        return
    
    from sklearn.metrics import confusion_matrix
    
    cm = confusion_matrix(y_true, y_pred)
    print(f"\n{model_name} æ··æ·†çŸ©é˜µ:")
    print("           é¢„æµ‹", "  ".join([f"{cls:10s}" for cls in CLASS_NAMES]))
    for i, cls_name in enumerate(CLASS_NAMES):
        print(f"çœŸå® {cls_name:10s}: {' '.join([f'{cm[i,j]:5d}' for j in range(len(CLASS_NAMES))])}")


def visualize_results(results):
    """ç”Ÿæˆç»“æœå¯è§†åŒ–å›¾è¡¨"""
    if not MATPLOTLIB_AVAILABLE:
        print("\nâš  matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å¯è§†åŒ–")
        return
    
    from sklearn.metrics import confusion_matrix, classification_report
    import seaborn as sns
    
    print("\n" + "="*60)
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    print("="*60)
    
    # è®¾ç½®å›¾è¡¨é£æ ¼
    plt.style.use('seaborn-v0_8-darkgrid')
    sns.set_palette("husl")
    
    # ============ å›¾è¡¨1: æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯” ============
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    
    model_names = []
    accuracies = []
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    for i, result in enumerate(results):
        if result:
            model_names.append(result['name'])
            accuracies.append(result['accuracy'])
    
    bars = ax1.bar(model_names, accuracies, color=colors[:len(model_names)], 
                   alpha=0.7, edgecolor='black', linewidth=2)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{acc:.4f}\n({acc*100:.2f}%)',
                ha='center', va='bottom', fontsize=12, fontweight='bold')
    
    ax1.set_ylabel('å‡†ç¡®ç‡ (Accuracy)', fontsize=12, fontweight='bold')
    ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax1.set_ylim(0, 1.1)
    ax1.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('å›¾è¡¨1_æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”.png', dpi=300, bbox_inches='tight')
    print("âœ“ å·²ä¿å­˜: å›¾è¡¨1_æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”.png")
    plt.close()
    
    # ============ å›¾è¡¨2: å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯” ============
    if len(results) > 0 and results[0]:
        fig2, ax2 = plt.subplots(figsize=(12, 6))
        
        model_names_detail = []
        class_accuracies = {cls: [] for cls in CLASS_NAMES}
        
        for result in results:
            if result:
                model_names_detail.append(result['name'])
                y_true = result['y_true']
                y_pred = result['y_pred']
                
                for i, cls_name in enumerate(CLASS_NAMES):
                    mask = y_true == i
                    if np.sum(mask) > 0:
                        acc = np.sum(y_pred[mask] == y_true[mask]) / np.sum(mask)
                        class_accuracies[cls_name].append(acc)
                    else:
                        class_accuracies[cls_name].append(0)
        
        x = np.arange(len(model_names_detail))
        width = 0.25
        
        for i, cls_name in enumerate(CLASS_NAMES):
            offset = (i - 1) * width
            bars = ax2.bar(x + offset, class_accuracies[cls_name], width,
                          label=cls_name, alpha=0.8, edgecolor='black')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                if height > 0:
                    ax2.text(bar.get_x() + bar.get_width()/2., height,
                            f'{height:.2f}',
                            ha='center', va='bottom', fontsize=9)
        
        ax2.set_xlabel('æ¨¡å‹', fontsize=12, fontweight='bold')
        ax2.set_ylabel('å‡†ç¡®ç‡ (Accuracy)', fontsize=12, fontweight='bold')
        ax2.set_title('å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(model_names_detail)
        ax2.legend(loc='lower right', fontsize=11)
        ax2.set_ylim(0, 1.1)
        ax2.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('å›¾è¡¨2_å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”.png', dpi=300, bbox_inches='tight')
        print("âœ“ å·²ä¿å­˜: å›¾è¡¨2_å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”.png")
        plt.close()
    
    # ============ å›¾è¡¨3: æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾ ============
    fig3, axes = plt.subplots(1, len([r for r in results if r]), 
                             figsize=(6*len([r for r in results if r]), 5))
    
    if not isinstance(axes, np.ndarray):
        axes = [axes]
    
    for idx, result in enumerate([r for r in results if r]):
        y_true = result['y_true']
        y_pred = result['y_pred']
        model_name = result['name']
        
        cm = confusion_matrix(y_true, y_pred)
        
        # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µï¼ˆæŒ‰è¡Œï¼‰
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',
                   xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,
                   ax=axes[idx], cbar=True, annot_kws={'size': 10})
        
        axes[idx].set_title(f'{model_name} æ··æ·†çŸ©é˜µ\n(ç™¾åˆ†æ¯”)', 
                           fontsize=12, fontweight='bold')
        axes[idx].set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=11, fontweight='bold')
        axes[idx].set_ylabel('çœŸå®æ ‡ç­¾', fontsize=11, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('å›¾è¡¨3_æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾.png', dpi=300, bbox_inches='tight')
    print("âœ“ å·²ä¿å­˜: å›¾è¡¨3_æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾.png")
    plt.close()
    
    # ============ å›¾è¡¨4: æ•°æ®é›†åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰ ============
    fig4, axes4 = plt.subplots(1, 3, figsize=(15, 4))
    
    splits = ['train', 'val', 'test']
    colors_pie = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    for ax, split in zip(axes4, splits):
        counts = []
        for cls in CLASS_NAMES:
            folder = os.path.join(DATASET_DIR, split, cls)
            if os.path.exists(folder):
                count = len([f for f in os.listdir(folder) 
                           if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
                counts.append(count)
            else:
                counts.append(0)
        
        wedges, texts, autotexts = ax.pie(counts, labels=CLASS_NAMES, autopct='%1.1f%%',
                                          colors=colors_pie, startangle=90,
                                          textprops={'fontsize': 10, 'fontweight': 'bold'})
        
        # æ·»åŠ æ•°å€¼
        total = sum(counts)
        ax.set_title(f'{split.upper()} é›†åˆ†å¸ƒ\n(æ€»æ•°: {total})', 
                    fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('å›¾è¡¨4_æ•°æ®é›†åˆ†å¸ƒ.png', dpi=300, bbox_inches='tight')
    print("âœ“ å·²ä¿å­˜: å›¾è¡¨4_æ•°æ®é›†åˆ†å¸ƒ.png")
    plt.close()
    
    # ============ å›¾è¡¨5: è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šï¼ˆä»…æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰ ============
    if results[0]:
        fig5, ax5 = plt.subplots(figsize=(10, 6))
        
        y_true = results[0]['y_true']
        y_pred = results[0]['y_pred']
        model_name = results[0]['name']
        
        # è·å–åˆ†ç±»æŠ¥å‘Šçš„å„é¡¹æŒ‡æ ‡
        report = classification_report(y_true, y_pred, output_dict=True, 
                                      target_names=CLASS_NAMES)
        
        metrics = ['precision', 'recall', 'f1-score']
        x = np.arange(len(CLASS_NAMES))
        width = 0.25
        
        for i, metric in enumerate(metrics):
            values = [report[cls][metric] for cls in CLASS_NAMES]
            offset = (i - 1) * width
            bars = ax5.bar(x + offset, values, width, label=metric.upper(),
                          alpha=0.8, edgecolor='black')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                ax5.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.2f}',
                        ha='center', va='bottom', fontsize=9)
        
        ax5.set_xlabel('ç±»åˆ«', fontsize=12, fontweight='bold')
        ax5.set_ylabel('åˆ†æ•°', fontsize=12, fontweight='bold')
        ax5.set_title(f'{model_name} æ¨¡å‹è¯¦ç»†è¯„ä¼°æŒ‡æ ‡', fontsize=14, fontweight='bold')
        ax5.set_xticks(x)
        ax5.set_xticklabels(CLASS_NAMES)
        ax5.legend(loc='lower right', fontsize=11)
        ax5.set_ylim(0, 1.1)
        ax5.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('å›¾è¡¨5_åˆ†ç±»è¯„ä¼°æŒ‡æ ‡.png', dpi=300, bbox_inches='tight')
        print("âœ“ å·²ä¿å­˜: å›¾è¡¨5_åˆ†ç±»è¯„ä¼°æŒ‡æ ‡.png")
        plt.close()
    
    print("\nâœ“ æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    print("  ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶:")
    print("  - å›¾è¡¨1_æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”.png")
    print("  - å›¾è¡¨2_å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”.png")
    print("  - å›¾è¡¨3_æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾.png")
    print("  - å›¾è¡¨4_æ•°æ®é›†åˆ†å¸ƒ.png")
    print("  - å›¾è¡¨5_åˆ†ç±»è¯„ä¼°æŒ‡æ ‡.png")


# ========================= ä¸»ç¨‹åº =========================

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "#"*60)
    print("# å£ç½©æ£€æµ‹ - æœºå™¨å­¦ä¹  + æ·±åº¦å­¦ä¹ å®Œæ•´é¡¹ç›®")
    print("#"*60)
    
    # æ­¥éª¤1ï¼šæ„å»ºæ•°æ®é›†
    success = build_classification_dataset()
    if not success:
        return
    
    # æ­¥éª¤2å’Œ3ï¼šè®­ç»ƒæ¨¡å‹
    results = []
    results.append(train_svm())
    results.append(train_resnet18(num_epochs=5))
    
    # æ­¥éª¤4ï¼šç»“æœæ€»ç»“
    print_results_summary(results)
    
    # æ··æ·†çŸ©é˜µ
    print("\n" + "="*60)
    print("æ··æ·†çŸ©é˜µè¯¦æƒ…")
    print("="*60)
    
    for result in results:
        if result:
            plot_confusion_matrix(result['y_true'], result['y_pred'], result['name'])
    
    # æ­¥éª¤5ï¼šç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    visualize_results(results)
    
    print("\n" + "#"*60)
    print("# âœ“ æ‰€æœ‰æµç¨‹å®Œæˆ!")
    print("#"*60)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - æ•°æ®é›†: {DATASET_DIR}/")
    print(f"  - æ¨¡å‹: {MODELS_DIR}/")
    print(f"  - å›¾è¡¨: å½“å‰ç›®å½•")
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®é›†å’Œæ¨¡å‹")
    print("  2. æŸ¥çœ‹ç”Ÿæˆçš„5å¼ ç»Ÿè®¡å›¾è¡¨")
    print("  3. ä¿®æ”¹æ¨¡å‹å‚æ•°è¿›è¡Œå®éªŒ")
    print("  4. å°è¯•å…¶ä»–ç®—æ³•æˆ–æ•°æ®é›†")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
